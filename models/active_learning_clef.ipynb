{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Machine Learning Models from scratch using Active Learning on HealthCLEF dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T17:18:45.407854Z",
     "start_time": "2019-08-29T17:18:44.249516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json \n",
    "import numpy as np\n",
    "import random \n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "import pickle \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle \n",
    "from libact.models import LogisticRegression\n",
    "from libact.models.svm import SVM\n",
    "from libact.models import SklearnProbaAdapter\n",
    "from libact.labelers import IdealLabeler\n",
    "from libact.query_strategies import RandomSampling, UncertaintySampling\n",
    "from libact.base.dataset import Dataset, import_libsvm_sparse\n",
    "from libact.models.sklearn_adapter import SklearnAdapter\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from utils import * \n",
    "\n",
    "# random seed for random shuffle \n",
    "seed = 100\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load document embeddings pre-trained/pre-calculated for this dataset\n",
    "- Insert DATASET_DIR path where all embeddings and dataset were downloaded. \n",
    "- Choose desired embedding BERT, BioBERT, Word2Vec, GloVe or TF-IDF. \n",
    "- Comment/Uncomment the desired embedding dictionary for active learning.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T17:20:06.828555Z",
     "start_time": "2019-08-29T17:18:45.758315Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_DIR = ''  # absolute path where dataset was downloaded and unzipped\n",
    "\n",
    "chosen_representation = 'GLOVE' # choose 'GLOVE', 'W2VEC', 'BERT', 'BioBERT' or 'TF-IDF' \n",
    "\n",
    "dict_embeddings, embedding_dim = return_embeddings_clef(chosen_representation, DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_embeddings.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metaparameters for active learning setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T17:31:52.551989Z",
     "start_time": "2019-08-29T17:31:52.547200Z"
    }
   },
   "outputs": [],
   "source": [
    "n_labeled = 5 # number of initial labeled documents  \n",
    "quota = 100 # total documents asked to the oracle \n",
    "batch = int(quota/10) # number of documents asked to the oracle on each iteration  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load clef dataset\n",
    "this dataset contains relations between topic ids that are medical questions and relevant/non relevant documents for each topic id. <br>\n",
    "We assume the HealthCLEF dataset has been downloaded in the same folder as the script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T17:31:58.097626Z",
     "start_time": "2019-08-29T17:31:53.206251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CD010339',\n",
       " 'CD011548',\n",
       " 'CD011549',\n",
       " 'CD009323',\n",
       " 'CD009591',\n",
       " 'CD009519',\n",
       " 'CD010409',\n",
       " 'CD009185',\n",
       " 'CD009944',\n",
       " 'CD012019',\n",
       " 'CD008686',\n",
       " 'CD009372',\n",
       " 'CD008782',\n",
       " 'CD010386',\n",
       " 'CD010632',\n",
       " 'CD010783',\n",
       " 'CD011145',\n",
       " 'CD010633',\n",
       " 'CD010896',\n",
       " 'CD010775',\n",
       " 'CD009786',\n",
       " 'CD011134',\n",
       " 'CD010542',\n",
       " 'CD008691',\n",
       " 'CD009020',\n",
       " 'CD007427',\n",
       " 'CD010023',\n",
       " 'CD008643',\n",
       " 'CD008760',\n",
       " 'CD009647',\n",
       " 'CD009925',\n",
       " 'CD011975',\n",
       " 'CD011984',\n",
       " 'CD008054',\n",
       " 'CD007431',\n",
       " 'CD010173',\n",
       " 'CD010276',\n",
       " 'CD007394',\n",
       " 'CD009135',\n",
       " 'CD009593',\n",
       " 'CD010438',\n",
       " 'CD010705',\n",
       " 'CD010771',\n",
       " 'CD008803',\n",
       " 'CD009551',\n",
       " 'CD010653',\n",
       " 'CD008081',\n",
       " 'CD010772',\n",
       " 'CD010860']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Medical questions clef \n",
    "matrix_doc_df = pd.read_csv('{}/datasets/CLEF_dataset.csv'.format(DATASET_DIR), sep='|')\n",
    "list_documents = list(dict_embeddings.keys())\n",
    "matrix_doc_df = matrix_doc_df[matrix_doc_df.pid.isin(list_documents)]\n",
    "matrices = list(matrix_doc_df.topic_id.unique())\n",
    "matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start active learning iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-29T17:31:48.854Z"
    }
   },
   "outputs": [],
   "source": [
    "# define models \n",
    "models = ['SVM_linear','RF', 'LR', 'MLP', 'SVM_rbf' ] \n",
    "\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    final_results = {}\n",
    "    \n",
    "    # initialize dictionary with results\n",
    "    for m in matrices: \n",
    "        final_results[m] = {'label':[], 'prediction': []}\n",
    "    \n",
    "    machine_learning_model = return_model(model)\n",
    "    \n",
    "    for m in matrices:\n",
    "        \n",
    "        matriz = matrix_doc_df[matrix_doc_df.topic_id == m]\n",
    "\n",
    "        # document vectors/embeddings \n",
    "        vectors = [ ]\n",
    "\n",
    "        for doc_id in matriz.pid:\n",
    "            vectors.append(dict_embeddings[str(doc_id)])\n",
    "\n",
    "        labels = [int(x) for x in matriz.rel]\n",
    "\n",
    "        # shuffle  \n",
    "        c = list(zip(vectors, labels))\n",
    "        random.shuffle(c)\n",
    "        vectors, labels = zip(*c)\n",
    "\n",
    "        # get dataset with observations without tags (None) and all tagged for ground-truth\n",
    "        X, y,X_test, y_test, ds_unlabeled, fully_labeled_ds = dataset_preprocesing(vectors,labels, n_labeled)\n",
    "\n",
    "        # the IdealLabeler takes labels from ground truth \n",
    "        lbr = IdealLabeler(fully_labeled_ds)\n",
    "\n",
    "        # select active learning strategy (uncertainty sampling or random sampling) \n",
    "        qs = UncertaintySampling(ds_unlabeled, model=machine_learning_model)\n",
    "        #qs = RandomSampling(ds_unlabeled)\n",
    "\n",
    "        for i in range(quota):\n",
    "            \n",
    "            ask_id = qs.make_query()\n",
    "\n",
    "            X, labels_new = zip(*ds_unlabeled.data)\n",
    "            lb = lbr.label(X[ask_id])\n",
    "            ds_unlabeled.update(ask_id, lb)\n",
    "            machine_learning_model.train(ds_unlabeled)\n",
    "\n",
    "            y_prob = [x[1] for x in machine_learning_model.predict_proba(X_test)]\n",
    "       \n",
    "            # after 10 documents asked to the oracle store results \n",
    "            if i%10 == 0:\n",
    "                final_results[m]['label'].append(y_test)\n",
    "                final_results[m]['prediction'].append(y_prob)\n",
    "                \n",
    "    # save model \n",
    "    print('saving model ...')\n",
    "    pickle.dump(machine_learning_model, open('{}_{}.sav'.format(model, chosen_representation), 'wb'))\n",
    "\n",
    "   \n",
    "     # save results \n",
    "    print('saving results...')\n",
    "    with open('results_{}_{}.json'.format(model, chosen_representation), 'w') as fp:\n",
    "        json.dump(final_results,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
